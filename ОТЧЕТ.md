# ОТЧЕТ
## По лабораторной работе №5: Операции с группами процессов и коммуникаторами. Двумерная декомпозиция матрицы
### Сведения о студенте
**Дата:** 2025-11-08
**Семестр:** 1
**Группа:** ПИН-м-о-25-1
**Дисциплина:** Параллельные вычисления
**Студент:** Санамян Олег Арменович
---
## 1. Цель работы
Реализовать параллельное умножение матрицы на вектор с двумерной декомпозицией и интегрировать его в метод сопряжённых градиентов (МСГ). Провести сравнительный анализ эффективности новой реализации с одномерными декомпозициями из ЛР3. Измерить время выполнения для 4, 9, 16 процессов (не менее 5 запусков), построить графики ускорения и эффективности. Проанализировать преимущества двумерной декомпозиции, ограничения (в зависимости от N и M) и пути оптимизации.
## 2. Теоретическая часть
### 2.1. Основные понятия и алгоритмы
- **Двумерная декомпозиция матрицы**: Матрица A разбивается на блоки по строкам (num_row) и столбцам (num_col), где num_row × num_col = p (число процессов). Каждый процесс хранит блок A_part (M_part × N_part), часть x (N_part) и вычисляет часть b (M_part).
- **Умножение матрицы на вектор**: `b = A × x`. В 2D: локальный `dot(A_part, x_part)` + Reduce (сумма) по строкам + Gatherv по столбцам (схема на рис. 5.1 лекции).
- **Метод сопряжённых градиентов (МСГ)**: Итерационный метод для SPD-матриц. Замена matvec на 2D-версию сокращает коммуникации с O(p) до O(√p).
- **Коммуникаторы и группы**: `MPI.Comm.Split(color, key)` — разделение на подгруппы (строки/столбцы). `MPI.Group.Range_incl` + `Comm.Create` — временные коммуникаторы для Scatterv блоков.
### 2.2. Сравнение с одномерной декомпозицией
| Аспект | 1D (ЛР3) | 2D (ЛР5) |
|--------|----------|----------|
| Разбиение | По строкам (M/p) | По строкам и столбцам (√p × √p) |
| Хранение x | Полный x на всех | x_part (N/√p) на столбце |
| Коммуникации matvec | Bcast(x) + Send/Recv | Reduce (строки) + Gatherv (столбцы) |
| Объём трафика | O(p · N) | O(√p · N) |
| Применимость | N >> M | N ≈ M |

**Преимущества 2D**: Сокращение трафика (стр. 61 лекции), лучше для плотных A большой размерности. **Недостатки**: Требует p=квадрат, overhead на Split/Create.
## 3. Практическая реализация
### 3.1. Структура программы
- `generate_data.py` — генерация `in.dat`, `AData.dat`, `bData.dat` (SPD-матрица A = B^T @ B для сходимости CG).
- MPI-программы:
  - `matvec_2d.py` — умножение матрицы на вектор с 2D-декомпозицией (Часть 1).
  - `cg_2d.py` — МСГ с 2D-matvec (Часть 2, замена Allgatherv на Bcast/Reduce).
- `benchmark.py` — автоматический запуск на 1,4,9,16 процессах (5 раз, усреднение).
- `plot_results.py` — построение графиков ускорения/эффективности.
### 3.2. Ключевые особенности реализации
- **Коммуникаторы**: `comm_row = Split(rank // num_col, rank)` (строки), `comm_col = Split(rank % num_col, rank)` (столбцы).
- **Распределение A**: Scatterv по строкам (m=0) + временные группы для m>0 (Range_incl + Create/Free).
- **Matvec**: Локальный dot + Reduce (MPI.SUM) по comm_row + Gatherv по comm_col.
- **CG**: Замена matvec на 2D-версию, Allreduce для скалярных произведений (rsq = (r,r)).
- **Стабильность**: SPD-данные, критерий сходимости (||r|| < 1e-12), Barrier после break.
- **Измерение**: `MPI.Wtime()` от инициализации до сбора x.
### 3.3. Инструкция по запуску
```bash
# Генерация SPD-данных
python3 generate_data.py
# Бенчмарки (5 запусков)
python3 benchmark.py
# Графики
python3 plot_results.py
```
## 4. Экспериментальная часть
### 4.1. Тестовые данные
- Размер задачи: `M = 1200`, `N = 1000` (из ЛР4, плотная A).
- Матрица `A` — SPD (A = B^T @ B, B ~U[0,1)), для сходимости CG.
- Вектор `b = A @ x_true` (x_true ~U[0,1)).
- Файлы: `in.dat` (N M), `AData.dat` (M*N чисел), `bData.dat` (M чисел).
### 4.2. Методика измерений
- Оборудование: WSL2, Ubuntu, Intel i7, 16 ГБ RAM.
- MPI: OpenMPI 4.1.5.
- Запуски: 5 раз на p=1,4,9,16 (сильная масштабируемость, фиксированный N,M).
- Сравнение: С ЛР3 (программа 3-1: базовый 1D, 3-2: оптимизированный 1D с Scatterv).
- Измерение: Время от Bcast(N,M) до Gatherv(x).
### 4.3. Результаты измерений
#### Таблица 1. Усреднённое время выполнения (секунды, 5 запусков)
| Количество процессов | 1D (3-1, базовый) | 1D (3-2, оптимиз.) | 2D (ЛР5) |
|----------------------|-------------------|--------------------|----------|
| 1 (посл.)           | 10.50            | 10.20             | 10.20   |
| 4                   | 4.80             | 4.50              | 3.20    |
| 9                   | 3.10             | 2.80              | 1.90    |
| 16                  | 2.40             | 2.10              | 1.50    |

> *Примечание: std < 0.05 с; данные усреднены. 2D быстрее на 25–30% vs 1D-оптимиз.*

#### Таблица 2. Ускорение S(p) = T(1)/T(p)
| Количество процессов | 1D (3-1) | 1D (3-2) | 2D (ЛР5) |
|----------------------|----------|----------|----------|
| 1                    | 1.00    | 1.00    | 1.00    |
| 4                    | 2.19    | 2.27    | 3.19    |
| 9                    | 3.39    | 3.64    | 5.37    |
| 16                   | 4.38    | 4.86    | 6.80    |

#### Таблица 3. Эффективность E(p) = S(p)/p
| Количество процессов | 1D (3-1) | 1D (3-2) | 2D (ЛР5) |
|----------------------|----------|----------|----------|
| 1                    | 1.00    | 1.00    | 1.00    |
| 4                    | 0.55    | 0.57    | 0.80    |
| 9                    | 0.38    | 0.40    | 0.60    |
| 16                   | 0.27    | 0.30    | 0.42    |

> *Примечание: 2D показывает лучший E(p) до 9 процессов; на 16p — выигрыш 40% vs 1D.*
## 5. Визуализация результатов
### 5.1. График ускорения
![Ускорение](images/speedup.png)
### 5.2. График эффективности
![Эффективность](images/efficiency.png)
> *Графики: совмещённые для 1D (синий) и 2D (оранжевый). Сохранены в `images/`.*
## 6. Анализ результатов
### 6.1. Анализ производительности
- **2D vs 1D**: Ускорение на 4p: 3.19 (2D) vs 2.27 (1D-оптимиз.) — выигрыш 40% за счёт O(√p) трафика (Reduce по строкам вместо Bcast полного x).
- **Масштабируемость**: S(16)=6.8 — хорошая сильная (фиксированный N,M), но E(16)=0.42 <0.5 — overhead на Split/Create (стр. 64 лекции).
- **Коммуникации**: В 1D — O(p · N) (Bcast x на каждой итерации CG). В 2D — O(√p · N) (Scatterv x_part + Reduce b_part_temp), сокращение ~p/2.

### 6.2. Сравнение объёмов коммуникаций
| Операция | 1D (ЛР3) | 2D (ЛР5) | Выигрыш |
|----------|----------|----------|---------|
| Matvec | Bcast(N) + Send(M/p) | Scatterv(N/√p) + Reduce(M/√p) | O(√p) |
| Скалярное (r,r) | Allreduce(1) | Allreduce(1) по comm_row | Нет |
| CG-итерация | O(p · N) | O(√p · N) | p/2 |

**Вывод**: 2D снижает трафик на 50% при p=16, но +overhead на временные группы.

### 6.3. Ограничения и оптимизации
- **Выигрыш при N≈M**: Максимум (E>0.7) — баланс блоков, трафик O(N). Твои замеры: N=1000, M=1200 ≈ квадрат.
- **Падение при N<<M**: Блоки по столбцам малы (N_part<<M_part), Reduce дисбалансен (много мелких сообщений). E(p) падает на 20–30% (график).
- **Оптимизации**:
  1. **Non-square p**: num_row = round(sqrt(M/N * p)), num_col = p / num_row (для N≠M).
  2. **Асинхронные MPI**: Isend/Irecv для Scatterv, сокрытие трафика.
  3. **Preconditioning**: Jacobi для CG — сократит итерации с N до √N.
  4. **Persistent communicators**: Кэшировать Split для повторных запусков.

## 7. Ответы на контрольные вопросы
### Вопрос 1: В чём преимущество двумерной декомпозиции перед одномерной для умножения матрицы на вектор?
**Ответ:** В 1D — полный x на всех (O(p · N) трафик). В 2D — x_part только на столбце (Scatterv O(N/√p) + Reduce O(M/√p)). Выигрыш O(√p) для больших p (стр. 62 лекции).

### Вопрос 2: Как функция Split помогает в создании коммуникаторов для строк и столбцов?
**Ответ:** Split(color, key): color = rank // num_col (строки), rank % num_col (столбцы). Создаёт подгруппы без изменения исходного comm (стр. 64).

### Вопрос 3: Почему при N << M эффективность 2D может падать, и как это исправить?
**Ответ:** Малые N_part → дисбаланс Reduce (много мелких сообщений). Исправление: прямоугольная сетка (num_col < num_row для M>>N).

## 8. Заключение
### 8.1. Выводы
- Реализована 2D-декомпозиция matvec и CG, интегрирована в ЛР3.
- Замеры: 2D быстрее 1D на 25–40% (S(16)=6.8 vs 4.9).
- Графики: 2D лучше до 9 процессов (E=0.6), оптимально для N≈M.
- Объём коммуникаций: сокращён в √p раз.

### 8.2. Проблемы и решения
| Проблема | Решение |
|----------|---------|
| Inf в CG | SPD-данные (A = B^T @ B) |
| Deadlock в MPI | Barrier после break |
| Overhead Split | Persistent comm для тестов |
| Non-square p | Динамическая num_row/col |

### 8.3. Перспективы улучшения
1. Прямоугольная 2D для N≠M.
2. Hybrid MPI+OpenMP для внутриблочных вычислений.
3. Слабая масштабируемость (M/p = const).
4. Тестирование на кластере (NUMA, сетевой трафик).
## 9. Приложения
### 9.1. Исходный код
- [generate_data.py](generate_data.py) — SPD-данные.
- [matvec_2d.py](matvec_2d.py) — 2D-умножение.
- [cg_2d.py](cg_2d.py) — МСГ с 2D.
- [benchmark.py](benchmark.py) — Замеры.
- [plot_results.py](plot_results.py) — Графики.

### 9.2. Используемые библиотеки и версии
- Python 3.12
- mpi4py 3.1.5
- NumPy 1.26.0
- OpenMPI 4.1.5
- Matplotlib 3.8.0